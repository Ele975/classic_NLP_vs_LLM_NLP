{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "edBgxvhUVoF0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6tj5gm_nVnOY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "387016cf-663d-49b4-ecbe-0c7c624c931e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai==0.28 in /usr/local/lib/python3.10/dist-packages (0.28.0)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (4.66.4)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (3.9.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2024.2.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (4.0.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install openai==0.28"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "52oGbUROV9og"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Key that gives an access to openai account\n",
        "openai.api_key = 'key_code'"
      ],
      "metadata": {
        "id": "NnNVppMMWC6U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "input text"
      ],
      "metadata": {
        "id": "jq2mLtpR_YoC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\"\"\n",
        "The company sells a number of different furniture products. These products are grouped into several product lines the identifier for a product is Product_ID, while the identifier for a product line is Product_Line_ID.  Referring to the customer invoice, we identify the following additional attributes for products: Product_Description, Product_Finish, and Unit_Price. Another attribute for product line is Product_Line_name. A product line may group any number of products, but must group at least one product. Each product must belong to exactly one product line. Customers submit orders for products. The identifier for an order is Order-ID, and another attribute is Order-Date. A customer may submit any number of orders, but need not submit any orders. Each order is submitted by exactly one customer. The identifier for a customer is Customer_ID. Other attributes include Customer_name and Customer_Address. A given customer order but request at least one product. Any product sold by Pine Valley Furniture may not be requested on any order, or or may be requested on one or more orders. An attribute associated with each order and product is Quantity, which is the number of units requested. Pine Valley Furniture has established sales territories for its customers. Each customer does business in one or more of these sales territories. The identifier for a sales territory is Territory_ID. A sales territory may have any number of customers, or may not have any customers doing business. Pine Valley Furniture Company has several salespersons. The identifier for a salesperson is Salesperson_ID. Other attributes include Salesperson_Name, Salesperson_Telephone, and Salesperson_Fax. A salesperson serves exactly one sales territory. Each sales territory is served by one or more salespersons. Each product is assembled from one or more raw materials. The identifier for the raw material entity is Material_ID other attributes include Unit_of_Measure and Unit_Price. Each raw material. May be assembled into one or more products. Raw materials are supplied by vendors. The identifier for a vendor is Vendor_ID. Other attributes include Vendor_Name and Vendor_Address. Each raw material can be suppled by one or more vendors. A vendor may supply any number of raw materials, or may not supply any raw materials to Pine Valley Furniture. An attribute of the relationship between vendor and raw material is Unit_Price. Pine Valley Furniture has established a number of work centers. The identifier for a work center is Work_Center_ID. Another attribute is Location. Each product is produced in one or more work centers. A work center may be used to produce any number of products, or may not be used to produce any products. The company has over 100 employees. The identifier for employee is Employee_ID. Other attributes are Employee_Name, EmployeeAddress, and Skill.  An employee may have more than one skill. A skill can be mastered by many employees. Each employee works in one or more work centers. A work center must have at least one employee working in that center, but may have any number of employees. Each employee has exactly one supervisor. An employee who is a supervisor may supervise any number of employees, but not all employees are supervisors.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "lf29iGMx_aHk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prompt tentatives"
      ],
      "metadata": {
        "id": "nw4Pps7H8gQ0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "few-shot prompting examples"
      ],
      "metadata": {
        "id": "J6-jGvxvWJEw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# parameter controlling randomness of the output\n",
        "temp = 0.0\n",
        "\n",
        "def get_completion(prompt, model=\"gpt-4\"):\n",
        "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "        temperature=temp, # this is the degree of randomness of the model's output\n",
        "    )\n",
        "    return response.choices[0].message[\"content\"]"
      ],
      "metadata": {
        "id": "c3GGgR_NWIM7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gpt_output():\n",
        "  answers = []\n",
        "  for i in range(1):\n",
        "      response = get_completion(prompt)\n",
        "      answers.append(response)\n",
        "\n",
        "  return answers[0]"
      ],
      "metadata": {
        "id": "m-MojHMIWoDy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prompt 1 - one-shot prompting\n",
        "\n",
        "bad example since additional attributes are inserted in the output which are not present in the input text"
      ],
      "metadata": {
        "id": "n9uso-6zhIxp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ex = \"\"\"\n",
        "A set of artists that are characterised by the name, status (active/stopped performing), their website and their multiple phone numbers.\n",
        "Moreover, for each artist we should store the year when they started performing and the year when they have stopped\n",
        "(if not active at the moment). Artists are associated with countries where they were/are based.\n",
        "Each artist has a set of releases: albums, singles or EPs. Each release should store information about the number of featured songs.\n",
        "We must not forget that songs can be a result of collaboration between artists. Songs should store a title, duration and a number of plays.\n",
        "Additionally, we should keep record of links that point to where the songs are stored on a server.\n",
        "We are supposed to display to users top-charts of songs in different countries. Moreover, we want to store information on upcoming concerts.\n",
        "The concerts are associated with the countries where they take place.\n",
        "The users should also be able to see the date, city, address, and the name of the venue.\n",
        "The concerts typically can involve multiple artists. For each user we should keep track of a username, email, and the user’s country.\n",
        "The users should be able to create playlists from a number of songs. A playlist is considered to be active if it is played more than once in a month.\n",
        "The users can follow artists as well as other users. It is also possible for a user to add other users’ playlists to the list of her/his own playlists.\n",
        "There are also a set of subscriptions that users can purchase.\n",
        "They differ in a number of playlists that can be created and the possibility to download tracks to a device for the offline playback.\n",
        "Subscriptions are priced differently depending on the country a user resides in. At a moment of time, a user can have only one type of subscription.\n",
        "\"\"\"\n",
        "\n",
        "output = \"\"\"\n",
        "ent_attr (containing the entities as keys and the attributes as values):\n",
        "{‘artist’: [‘start year’, ‘end year’, ‘name’, ‘status’, ‘website’, ‘ID’], ‘release’: [‘ID’, ‘number of featured songs’], ‘song’: [‘title’, ‘duration’, ‘number of plays’, ‘link’, ‘ID’], ‘playlist’: [‘status’, ‘last play’, ‘name’, ‘ID’], ‘top-chart’: [‘ID’], ‘country’: [‘name’], ‘concert’: [‘date’, ‘city’, ‘address’, ‘name’, ‘ID’], ‘subscription’: [‘ID’, ‘download’, ‘number of playlist’], ‘user’: [‘ID’, ‘username’, ‘email’]}\n",
        "Cardinality (containing the cardinality and the entities of the relationship):\n",
        "[[(0:N), ‘artist’, ‘user’], [(0:N), ‘user’, ‘artist’], [(1:N),‘artist’, ‘release’], [(1:N)‘release’, ‘artist’], [(1:N),‘artist’, ‘song’], [(1:N),‘song’, ‘artist’], [(1:N),‘artist’, ‘country’], [(0:N)‘country’,’artist’], [(0:N),‘artist’, ‘concert’], [(1:N),‘concert’, ‘artist’], [(1:N),‘release’, ‘song’], [(1:N),‘song’,’release’], [(0:N),‘song’, ‘playlist’], [(1:N),‘playlist’, ‘song’], [(0:N),‘song’, ‘top-chart’], [(1:N),‘top-chart’, ‘song’], [(0:N),‘playlist’, ‘user’], [(0:N),‘user’, ‘playlist’], [(1:1),‘playlist’, ‘user’], [(0:N),‘user’, ‘playlist’], [(1:1),‘top-chart’, ‘country’], [(1:1),‘country’, ‘top-chart’], [(0:N),‘country’, ‘concert’], [(1:1),‘concert’, ‘country’], [(0:N),‘country’, ‘subscription’], [(1:N),‘subscription’, ‘country’], [(0:N),‘country’, ‘user’], [(1:1),‘user’, ‘country’], [(0:N),‘user’, ‘user’], [(0:N),‘user’, ‘user’], [(1:1),‘user’, ‘subscription’], [(0:N),‘subscription’, ‘user’]]\n",
        "cardinality_attr (containing the entities and their unique attributes):\n",
        "[[1, ‘artist’,’ID’], [2, 'artist', 'phone number'],[1, ‘release’,’ID’], [1,’song’, ‘ID’], [1, ‘playlist’,’ID’], [1,’top-chart’,’ID’], [1,’country’,’name’], [1,’concert’,’ID],[1,’user’,’ID’],[1,’subscription’,’ID’]]\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "x33jUKWHjh5k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "requirements = f\"\"\"\n",
        "{text}\n",
        "\"\"\"\n",
        "\n",
        "prompt = f\"\"\"\n",
        "The task is to extract elements for creating an Entity-Relationship Diagram from a given natural language text.\n",
        "These elements should be: entity types, attributes, unique attributes (which identify each entity of an entity type),\n",
        "multivalued attributes, composite attributes, relationship between entities and the cardinality for each relationship\n",
        "(cardinality in both directions of the relationship).\n",
        "An example of the task required is given below, where the 'input text' is the original text and the 'output' are the elements for the entity-relationship diagram:\n",
        "\n",
        "Input text:\n",
        "'\n",
        "{ex}\n",
        "'\n",
        "\n",
        "Output:\n",
        "'\n",
        "{output}\n",
        "'\n",
        "Given the text in the triple backticks, extract the required elements for the build of an ER-diagram:\n",
        "\n",
        "\n",
        "Text:\n",
        "```{requirements}```\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "yxXbEjyJhJsh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_text = gpt_output()\n",
        "print(input_text)"
      ],
      "metadata": {
        "id": "jm4FiE60hOZL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prompt 2 - zero-shot prompting\n",
        "\n",
        "the structure of the output passed is too complex and introduce some errors"
      ],
      "metadata": {
        "id": "c3eLca4YHO8v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "requirements = f\"\"\"\n",
        "{text}\n",
        "\"\"\"\n",
        "\n",
        "prompt = f\"\"\"\n",
        "The task is to extract elements for creating an Entity-Relationship Diagram from a given natural language text.\n",
        "These elements should be: entity types, attributes, unique attributes (which identify each entity of an entity type),\n",
        "multivalued attributes, composite attributes, relationship between entities and the cardinality for each relationship\n",
        "(cardinality in both directions of the relationship).\n",
        "You need to create two dictionaries and two arrays for each type of element you have to extract, for a total of 4 structure :\n",
        "1. A dictionary named 'ent_attr' containing as keys all the entities extracted from the input text and as values of each key an array containing all the attributes associated to that entity. For example: {{'person':['id', 'name'], 'teacher':['age']}}\n",
        "2. A dictionary named 'composite_attr' containing as key the entity the composite attribute belongs to, and as values an array made of at least two elements for each entity; the first element is the composite attribute, and the following elements are all the simple attributes which compose the composite attribute. For example: {{'person':['name', 'first name', 'last name']}}\n",
        "3. An array named 'cardinality' where each elements contains 4 data: the first one is a tuple containing the cardinality of the relationship (the quantity of the first entity followed by the quantity of the second entity), the second data is the first entity of the relationship, the third data the second entity, and the last data is the verb of the relationship. The types of the cardinality data can be 1 (exactly one), 01 (zero or one), 02 (zero or more), 12 (one or more). e.g. [[(1, 1), 'person', 'car', 'own')]].\n",
        "4. An array named 'cardinality_attr' containing the special attributes (unique and multivalued attributes). Each element contains 3 data: the first one is the type of attribue (1 for unique attributes, 2 for multivalued attributes), the second data is the entity associated to that attribute, and the third data is the unique or multivalued attribute. E.g. [[1, 'user', 'code'], [2, 'person', 'phone number']].\n",
        "All that is put in these arrays or dictionaries should be set to its singular form. If in the text there are not both the two cardinalities for each relationship among two entities, try to figure out the cardinality by intuition analyzing the entities involved.\n",
        "Print in order the ent_attr, composite_attr, cardinality and cardinality_attr filled with the data you have been able to extract.\n",
        "The input text from which you have to extract the elements for the Entity-Relastionship Diagram is given below in the triple backticks:\n",
        "\n",
        "\n",
        "Text:\n",
        "```{requirements}```\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "moAE6A8PWn0K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_text = gpt_output()\n",
        "print(input_text)"
      ],
      "metadata": {
        "id": "dM8d0b9JgGzd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prompt 3 - zero-shot prompting\n",
        "\n",
        "better but need to fix the cardinalities including the zero (zero or more, zero or one)"
      ],
      "metadata": {
        "id": "e1A2IxASHQde"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "requirements = f\"\"\"\n",
        "{text}\n",
        "\"\"\"\n",
        "\n",
        "prompt = f\"\"\"\n",
        "The task is to extract elements for creating an Entity-Relationship Diagram from a given natural language text.\n",
        "These elements should be: entity types, attributes, unique attributes (which identify each entity of an entity type),\n",
        "multivalued attributes, composite attributes, relationship between entities and the cardinality for each relationship\n",
        "(cardinality in both directions of the relationship). Given the text in the triple backticks, extract the required elements for the build of an ER-diagram:\n",
        "\n",
        "\n",
        "Text:\n",
        "```{requirements}```\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "Pdyf72dZHRzr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_text = gpt_output()\n",
        "print(input_text)"
      ],
      "metadata": {
        "id": "4lRpThV3AyHX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prompt 5 - okay but can be better for the zeros in the cardinality"
      ],
      "metadata": {
        "id": "hAiBF8zPp8mU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "requirements = f\"\"\"\n",
        "{text}\n",
        "\"\"\"\n",
        "\n",
        "prompt = f\"\"\"\n",
        "The task is to extract elements for creating an Entity-Relationship Diagram from a given natural language text.\n",
        "These elements should be: entity types, attributes, unique attributes (which identify each entity of an entity type),\n",
        "multivalued attributes, composite attributes, relationship between entities and the cardinality for each relationship\n",
        "(one-to-many, many-to-many and specify trying to understand by the entities if the zero is included even if it is not written). Given the text in the triple backticks, extract the required elements for the build of an ER-diagram:\n",
        "\n",
        "\n",
        "Text:\n",
        "```{requirements}```\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "nOb-uqzUAydU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_text = gpt_output()\n",
        "print(input_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iN0GLAsyA0FI",
        "outputId": "8fb2d2a5-bca1-4ffb-802e-4a64d8f602aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Entity Types: Company, Furniture Products, Product Lines, Customer Invoice, Customers, Orders, Sales Territories, Salespersons, Raw Materials, Vendors, Work Centers, Employees, Supervisors.\n",
            "\n",
            "Attributes: \n",
            "- Furniture Products: Product_ID, Product_Description, Product_Finish, Unit_Price.\n",
            "- Product Lines: Product_Line_ID, Product_Line_name.\n",
            "- Customer Invoice: Product_ID, Product_Description, Product_Finish, Unit_Price.\n",
            "- Customers: Customer_ID, Customer_name, Customer_Address.\n",
            "- Orders: Order-ID, Order-Date, Quantity.\n",
            "- Sales Territories: Territory_ID.\n",
            "- Salespersons: Salesperson_ID, Salesperson_Name, Salesperson_Telephone, Salesperson_Fax.\n",
            "- Raw Materials: Material_ID, Unit_of_Measure, Unit_Price.\n",
            "- Vendors: Vendor_ID, Vendor_Name, Vendor_Address, Unit_Price.\n",
            "- Work Centers: Work_Center_ID, Location.\n",
            "- Employees: Employee_ID, Employee_Name, EmployeeAddress, Skill.\n",
            "\n",
            "Unique Attributes: \n",
            "- Furniture Products: Product_ID.\n",
            "- Product Lines: Product_Line_ID.\n",
            "- Customers: Customer_ID.\n",
            "- Orders: Order-ID.\n",
            "- Sales Territories: Territory_ID.\n",
            "- Salespersons: Salesperson_ID.\n",
            "- Raw Materials: Material_ID.\n",
            "- Vendors: Vendor_ID.\n",
            "- Work Centers: Work_Center_ID.\n",
            "- Employees: Employee_ID.\n",
            "\n",
            "Multivalued Attributes: \n",
            "- Employees: Skill.\n",
            "\n",
            "Composite Attributes: None mentioned.\n",
            "\n",
            "Relationships: \n",
            "- A product line groups products.\n",
            "- Customers submit orders.\n",
            "- Orders are submitted by customers.\n",
            "- Customers do business in sales territories.\n",
            "- Salespersons serve sales territories.\n",
            "- Products are assembled from raw materials.\n",
            "- Raw materials are supplied by vendors.\n",
            "- Vendors supply raw materials.\n",
            "- Products are produced in work centers.\n",
            "- Employees work in work centers.\n",
            "- Supervisors supervise employees.\n",
            "\n",
            "Cardinality: \n",
            "- One-to-many: Product line to products, Customer to orders, Salesperson to sales territory, Product to raw materials, Vendor to raw materials, Work center to products, Employee to work centers, Supervisor to employees.\n",
            "- Many-to-many: Customer to sales territories, Sales territory to salespersons, Raw material to products, Raw material to vendors, Product to work centers, Employee to skills.\n",
            "- Zero included: Product line to products (at least one), Customer to orders (zero or more), Sales territory to customers (zero or more), Vendor to raw materials (zero or more), Work center to products (zero or more).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[3, 0, 0],\n",
              " [1, 2, 2],\n",
              " [5, 8, 2],\n",
              " [2, 1, 2],\n",
              " [2, 1, 2],\n",
              " [2, 1, 0],\n",
              " [6, 0, 0],\n",
              " [1, 2, 1],\n",
              " [3, 4, 1],\n",
              " [4, 0, 0]]"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prompt 6 - okay, seems the best since can understand when the zeros should be included in cardinalities"
      ],
      "metadata": {
        "id": "jAq4_XT-p90i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "requirements = f\"\"\"\n",
        "{text}\n",
        "\"\"\"\n",
        "\n",
        "prompt = f\"\"\"\n",
        "The task is to extract elements for creating an Entity-Relationship Diagram from a given natural language text.\n",
        "These elements should be: entity types, attributes, unique attributes (which identify each entity of an entity type),\n",
        "multivalued attributes, composite attributes, relationship between entities and cardinalities (01, 1, 0N, N), where 01 is 'zero or one', 1 is 'exactly one', 0N is 'zero or more' and N is 'one or more'.\n",
        "Given the text in the triple backticks, extract the required elements for the build of an ER-diagram:\n",
        "\n",
        "\n",
        "Text:\n",
        "```{requirements}```\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "jecr2kcXDv3s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_text = gpt_output()\n",
        "print(input_text)"
      ],
      "metadata": {
        "id": "PHCOno-PDxSe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prompt 7 - okay"
      ],
      "metadata": {
        "id": "4AEIoBp5th5w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "requirements = f\"\"\"\n",
        "{text}\n",
        "\"\"\"\n",
        "\n",
        "prompt = f\"\"\"\n",
        "The task is to extract elements for creating an Entity-Relationship Diagram from a given natural language text.\n",
        "These elements should be: entity types, attributes, unique attributes (which identify each entity of an entity type),\n",
        "multivalued attributes, composite attributes, relationship between entities and cardinalities (01, 1, 0N, N), where 01 is 'zero or one', 1 is 'exactly one', 0N is 'zero or more' and N is 'one or more'.\n",
        "Attention to not create entity types which doesn't exist (if you are not certain about the entity, don't output it). Given the text in the triple backticks, extract the required elements for the build of an ER-diagram:\n",
        "\n",
        "\n",
        "Text:\n",
        "```{requirements}```\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "zwPog7zStntU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_text = gpt_output()\n",
        "print(input_text)"
      ],
      "metadata": {
        "id": "VbYXerEHvHSi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prompts evaluation with training set\n",
        "For the evaluation we take into consideration only the best ones which are the prompts number 5,6 and 7 and we evaluate them only using entity types and attributes"
      ],
      "metadata": {
        "id": "pE2oQFGQ8k4l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# array for each prompt where each element contains true positives, false positives and false negatives\n",
        "prompt5 = [[47, 12, 13], [7,11,0], [33,0,0], [30,2,0], [16,4,1], [8,2,0], [12,17,3], [14,5,0], [7,11,0], [28,8,1], [18,1,1], [27,0,0], [13,2,3], [10,1,1], [34,1,0], [6,4,0], [19,2,0], [25,11,5], [10,0,0]]\n",
        "prompt5_1 = [[47, 12, 13], [15,3,0], [33,0,0], [30,2,0], [16,4,1],[8,2,0], [14,15,4], [19,0,0], [15,3,0], [28,8,1], [18,1,1], [27,0,0], [13,2,3], [10,1,1], [34,1,0], [6,4,0], [19,2,0], [25,11,5], [10,0,0]]\n",
        "prompt6 = [[40,15,22], [7, 0, 0], [33,0,0], [30,0,0],[16,4,1], [8,2,0], [13,17,3], [14,6,0], [7,10,0], [28,8,1], [18,1,1], [27,0,0], [14,1,2], [10,0,0], [34,1,0], [6,3,0], [19,2,0], [23,4,10], [10,0,0]]\n",
        "prompt7 = [[40, 21, 22], [7,0,0], [33,0,0], [30,0,0], [16,4,1], [8,7,0], [10,17,4], [14,6,0], [7,10,0], [30,12,0], [18,1,1], [27,0,0], [13,2,2], [10,0,0], [34,1,0], [6,4,0], [19,2,0], [23,9,9], [10,0,0]]"
      ],
      "metadata": {
        "id": "3iRSrzjkA3E4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "average training set"
      ],
      "metadata": {
        "id": "qZCZ27vRX7IU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np_prompt5 = np.array(prompt5)\n",
        "np_prompt5_1 = np.array(prompt5_1)\n",
        "np_prompt6 = np.array(prompt6)\n",
        "np_prompt7 = np.array(prompt7)\n",
        "\n",
        "\n",
        "sum_prompt5 = np.sum(np_prompt5, axis=0)\n",
        "sum_prompt5_1 = np.sum(np_prompt5_1, axis=0)\n",
        "sum_prompt6 = np.sum(np_prompt6, axis=0)\n",
        "sum_prompt7 = np.sum(np_prompt7, axis=0)\n",
        "\n",
        "# print sum of true positives, false positives and false negatives for each main prompt\n",
        "print('tp, fp, fn prompt 5:',sum_prompt5)\n",
        "print('tp, fp, fn prompt 5, evaluation 1:',sum_prompt5_1)\n",
        "print('tp, fp, fn prompt 6:',sum_prompt6)\n",
        "print('tp, fp, fn prompt 7:',sum_prompt7)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ojntDQwsX8yJ",
        "outputId": "6d56a9b4-9281-4948-a7c6-beee49f16baf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[364  94  28]\n",
            "[387  71  29]\n",
            "[357  74  40]\n",
            "[355  96  39]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Functions for precision, recall and F1 score"
      ],
      "metadata": {
        "id": "_k50boyeSBKm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def precision(tp, fp):\n",
        "  if tp + fp == 0:\n",
        "    return 0\n",
        "  else:\n",
        "    return tp/(tp + fp)"
      ],
      "metadata": {
        "id": "FzadE3Q7ZhGo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def recall(tp, fn):\n",
        "  if tp + fn == 0:\n",
        "    return 0\n",
        "  else:\n",
        "    return tp/(tp + fn)"
      ],
      "metadata": {
        "id": "i_MnDHeVZp8s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def f1(precision,recall):\n",
        "  if precision + recall == 0:\n",
        "    return 0\n",
        "  else:\n",
        "    return 2 * ((precision * recall) / (precision + recall))"
      ],
      "metadata": {
        "id": "qByec0a_Z29K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "prompt 5\n",
        "\n",
        "precision, recall and F1 score"
      ],
      "metadata": {
        "id": "h2eTfgGuaR1z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prec5 = precision(sum_prompt5[0], sum_prompt5[1])\n",
        "rec5 = recall(sum_prompt5[0], sum_prompt5[2])\n",
        "f1_5 = f1(prec5, rec5)\n",
        "\n",
        "print('precision:',prec5)\n",
        "print('recall:'rec5)\n",
        "print('F1 score:'f1_5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1uh2EJF1aMim",
        "outputId": "347081e0-831d-4f54-bb05-2e501d264691"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7947598253275109\n",
            "0.9285714285714286\n",
            "0.856470588235294\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prompt 5.1\n",
        "\n",
        "precision, recall and F1 score"
      ],
      "metadata": {
        "id": "lzxITE35dJYz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prec5_1 = precision(sum_prompt5_1[0], sum_prompt5_1[1])\n",
        "rec5_1 = recall(sum_prompt5_1[0], sum_prompt5_1[2])\n",
        "f1_5_1 = f1(prec5_1, rec5_1)\n",
        "\n",
        "print('precision:',prec5_1)\n",
        "print('recall:'rec5_1)\n",
        "print('F1 score:'f1_5_1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u_WCr3lMalvj",
        "outputId": "c3dac2c9-da79-4a9f-90ab-02022d39f443"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8449781659388647\n",
            "0.9302884615384616\n",
            "0.88558352402746\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prompt 6\n",
        "\n",
        "precision, recall and F1 score"
      ],
      "metadata": {
        "id": "kHvbXJPddLhA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prec6 = precision(sum_prompt6[0], sum_prompt6[1])\n",
        "rec6 = recall(sum_prompt6[0], sum_prompt6[2])\n",
        "f1_6 = f1(prec6, rec6)\n",
        "\n",
        "print('precision:',prec6)\n",
        "print('recall:'rec6)\n",
        "print('F1 score:'f1_6)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m2DodR0pamPm",
        "outputId": "77d05867-d976-443b-b3cc-aedcd205158b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8283062645011601\n",
            "0.8992443324937027\n",
            "0.8623188405797101\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prompt 7\n",
        "\n",
        "precision, recall and F1 score"
      ],
      "metadata": {
        "id": "coMMgdCMdMUc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prec7 = precision(sum_prompt7[0], sum_prompt7[1])\n",
        "rec7 = recall(sum_prompt7[0], sum_prompt7[2])\n",
        "f1_7 = f1(prec7, rec7)\n",
        "\n",
        "print('precision:',prec7)\n",
        "print('recall:'rec7)\n",
        "print('F1 score:'f1_7)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "54VRosGXamte",
        "outputId": "43a64753-f386-42e9-ff8c-f7090c37ebab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7871396895787139\n",
            "0.9010152284263959\n",
            "0.8402366863905325\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Best prompt (5.1) evaluation with test set"
      ],
      "metadata": {
        "id": "8PCSR-2q7tbX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_prompt = [[12,0,0], [27,2,0], [31,11,4], [33,4,2], [18,0,0], [29,6,2], [27,1,1], [41,1,0], [35,6,1], [13,0,1], [54,9,7]]"
      ],
      "metadata": {
        "id": "0O1wwwJl73DD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_np_prompt = np.array(best_prompt)\n",
        "sum_best_prompt = np.sum(best_np_prompt, axis=0)\n",
        "print('tp, fp and fn:',sum_best_prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y2MTJx9mEguP",
        "outputId": "d995c203-907e-4269-ad95-120341b6dfe5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[320  40  18]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_prec = precision(sum_best_prompt[0], sum_best_prompt[1])\n",
        "best_rec = recall(sum_best_prompt[0], sum_best_prompt[2])\n",
        "best_f1 = f1(best_prec, best_rec)\n",
        "\n",
        "print('precision:',best_prec)\n",
        "print('recall:',best_rec)\n",
        "print('F1 score:',best_f1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tX36oFajFDGu",
        "outputId": "4176dce2-59bc-4c8d-d702-1cf8006ab6a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8888888888888888\n",
            "0.9467455621301775\n",
            "0.9169054441260744\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Best prompt (5.1) evaluation with training set"
      ],
      "metadata": {
        "id": "JeQfuCCIlhhW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_prompt_train = [[48,12,8], [34,1,0], [28,9,2], [26,4,6], [27,0,0],[12,1,3], [32,10,1], [18,1,1], [19,1,0],[32,1,1],[16,3,1], [30,0,0],[19,3,0],[14,18,5],[15,3,0], [20,6,0], [17,0,0],[6,2,0],[11,0,0],[9,0,0],[15,3,0]]"
      ],
      "metadata": {
        "id": "FNIRtnGUlo3y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_np_prompt_train = np.array(best_prompt_train)\n",
        "sum_best_prompt_train = np.sum(best_np_prompt_train, axis=0)\n",
        "print('tp, fp and fn:', sum_best_prompt_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BXCdGat0lrnA",
        "outputId": "ab017686-e910-412f-b67d-7e372c58275a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[448  78  28]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_prec_train = precision(sum_best_prompt_train[0], sum_best_prompt_train[1])\n",
        "best_rec_train = recall(sum_best_prompt_train[0], sum_best_prompt_train[2])\n",
        "best_f1_train = f1(best_prec_train, best_rec_train)\n",
        "\n",
        "print('precision:',best_prec_train)\n",
        "print('recall:',best_rec_train)\n",
        "print('F1 score:'best_f1_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hobQWK0ilwZe",
        "outputId": "6f7a6b78-c1a0-4e46-b29a-0f40691ea860"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8517110266159695\n",
            "0.9411764705882353\n",
            "0.8942115768463074\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Best prompt (5.1) separated evaluation with training set\n",
        "Split results of elements for each dataset.\n",
        "For the training set only entities and attributes should be taken into consideration"
      ],
      "metadata": {
        "id": "IbHKPD4vIzEo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# training set\n",
        "\n",
        "ent = [[5,2,0], [9,0,0],[6,0,0], [5,1,0], [4,2,0], [3,0,0], [3,0,0],[3,0,0], [3,2,0], [5,0,0], [3,2,0], [3,0,0], [4,0,0], [3,0,0], [4,0,0],[2,0,0], [3,1,0], [1,1,0],[2,0,0],[4,0,0]]\n",
        "attr = [[15,5,0], [22,4,4], [17,1,0], [13,2,3], [16,1,0], [10,1,0], [10,1,0], [9,1,0], [7,6,2], [15,0,0], [3,8,0], [9,0,0], [4,3,0], [8,0,0], [16,0,0],[5,0,0],[7,0,0],[3,1,0],[4,0,0],[4,3,0]]\n",
        "unique = [[4,0,0], [6,3,3], [6,0,0], [4,2,0], [5,1,1], [3,0,0], [3,0,0],[3,0,0], [2,3,1],[5,0,0], [3,2,0], [5,0,0], [4,0,0], [3,0,0],[4,0,0],[2,0,0],[2,0,0],[1,0,0],[2,0,0],[4,0,0]]\n",
        "composite = [[0,0,0], [0,0,0], [0,0,0], [0,0,0], [0,0,0], [0,0,0], [0,0,0],[0,0,0], [0,0,0],[0,0,0], [0,0,0], [0,0,0], [0,0,0],[0,0,0],[0,0,0],[0,0,0],[0,0,0],[0,0,0],[3,0,0],[0,0,0]]\n",
        "multivalued = [[0,0,0], [0,0,0], [0,0,0], [0,0,0], [0,1,0], [0,0,0], [0,1,0], [0,0,0], [0,0,0], [0,0,0], [0,0,0], [0,0,0], [0,0,0],[0,0,0],[0,0,0],[0,0,0],[0,0,0],[0,0,0],[0,0,0],[0,0,0]]\n",
        "relation = [[4,4,1], [11,1,5], [5,0,0], [4,0,2], [5,1,0], [2,0,0], [3,0,0],[1,2,1], [2,3,2], [5,0,0], [5,0,0], [2,0,0], [3,0,0],[3,0,0], [3,0,0],[1,0,0],[1,2,2],[1,1,0],[1,0,0],[3,0,0]]"
      ],
      "metadata": {
        "id": "fdtEQBYlvMsO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ent_np_prompt_train = np.array(ent)\n",
        "attr_np_prompt_train = np.array(attr)\n",
        "unique_np_prompt_train = np.array(unique)\n",
        "composite_np_prompt_train = np.array(composite)\n",
        "multivalued_np_prompt_train = np.array(multivalued)\n",
        "relation_np_prompt_train = np.array(relation)\n",
        "\n",
        "sum_ent_prompt_train = np.sum(ent_np_prompt_train, axis=0)\n",
        "sum_attr_prompt_train = np.sum(attr_np_prompt_train, axis=0)\n",
        "sum_unique_prompt_train = np.sum(unique_np_prompt_train, axis=0)\n",
        "sum_composite_prompt_train = np.sum(composite_np_prompt_train, axis=0)\n",
        "sum_multivalued_prompt_train = np.sum(multivalued_np_prompt_train, axis=0)\n",
        "sum_relation_prompt_train = np.sum(relation_np_prompt_train, axis=0)\n",
        "\n",
        "print('ent tp, fp and fn:',sum_ent_prompt_train)\n",
        "print('attr tp, fp and fn:',sum_attr_prompt_train)\n",
        "print('unique tp, fp and fn:',sum_unique_prompt_train)\n",
        "print('composite tp, fp and fn:',sum_composite_prompt_train)\n",
        "print('multivalued tp, fp and fn:',sum_multivalued_prompt_train)\n",
        "print('relationships tp, fp and fn:',sum_relation_prompt_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YOyYffXYvk05",
        "outputId": "04636e37-a1ad-4e5b-f09c-936da34eed7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ent: [75 11  0]\n",
            "attr: [197  37   9]\n",
            "unique: [71 11  5]\n",
            "composite: [3 0 0]\n",
            "multivalued: [0 2 0]\n",
            "relationships: [65 14 13]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ent_prec_train = precision(sum_ent_prompt_train[0], sum_ent_prompt_train[1])\n",
        "ent_rec_train = recall(sum_ent_prompt_train[0], sum_ent_prompt_train[2])\n",
        "ent_f1_train = f1(ent_prec_train, ent_rec_train)\n",
        "\n",
        "print('ent precision, recall and F1 score:', ent_prec_train, ent_rec_train, ent_f1_train)\n",
        "\n",
        "attr_prec_train = precision(sum_attr_prompt_train[0], sum_attr_prompt_train[1])\n",
        "attr_rec_train = recall(sum_attr_prompt_train[0], sum_attr_prompt_train[2])\n",
        "attr_f1_train = f1(attr_prec_train, attr_rec_train)\n",
        "\n",
        "print('attr precision, recall and F1 score:', attr_prec_train, attr_rec_train, attr_f1_train)\n",
        "\n",
        "unique_prec_train = precision(sum_unique_prompt_train[0], sum_unique_prompt_train[1])\n",
        "unique_rec_train = recall(sum_unique_prompt_train[0], sum_unique_prompt_train[2])\n",
        "unique_f1_train = f1(unique_prec_train, unique_rec_train)\n",
        "\n",
        "print('unique precision, recall and F1 score:', unique_prec_train, unique_rec_train, unique_f1_train)\n",
        "\n",
        "composite_prec_train = precision(sum_composite_prompt_train[0], sum_composite_prompt_train[1])\n",
        "composite_rec_train = recall(sum_composite_prompt_train[0], sum_composite_prompt_train[2])\n",
        "composite_f1_train = f1(composite_prec_train, composite_rec_train)\n",
        "\n",
        "print('composite precision, recall and F1 score:', composite_prec_train, composite_rec_train, composite_f1_train)\n",
        "\n",
        "multivalued_prec_train = precision(sum_multivalued_prompt_train[0], sum_multivalued_prompt_train[1])\n",
        "multivalued_rec_train = recall(sum_multivalued_prompt_train[0], sum_multivalued_prompt_train[2])\n",
        "multivalued_f1_train = f1(multivalued_prec_train, multivalued_rec_train)\n",
        "\n",
        "print('multivalued precision, recall and F1 score:', multivalued_prec_train, multivalued_rec_train, multivalued_f1_train)\n",
        "\n",
        "relation_prec_train = precision(sum_relation_prompt_train[0], sum_relation_prompt_train[1])\n",
        "relation_rec_train = recall(sum_relation_prompt_train[0], sum_relation_prompt_train[2])\n",
        "relation_f1_train = f1(relation_prec_train, relation_rec_train)\n",
        "\n",
        "print('relation precision, recall and F1 score:', relation_prec_train, relation_rec_train, relation_f1_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P1pGEyXZ0gA_",
        "outputId": "4b7ad957-efa7-45b1-df9b-100332d3c709"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ent: 0.872093023255814 1.0 0.9316770186335404\n",
            "attr: 0.8418803418803419 0.9563106796116505 0.8954545454545455\n",
            "unique: 0.8658536585365854 0.9342105263157895 0.8987341772151899\n",
            "composite: 1.0 1.0 1.0\n",
            "multivalued: 0.0 0 0\n",
            "relation: 0.8227848101265823 0.8333333333333334 0.8280254777070064\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Best prompt (5.1) separated evaluation with test set"
      ],
      "metadata": {
        "id": "K5tMnqQ2vIGS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# test set\n",
        "\n",
        "ent = [[3,0,0], [4,1,0],[6,2,0],[5,1,0],[4,1,0],[3,0,0],[5,0,0],[4,0,0],[4,1,0],[5,0,0],[10,3,1]]\n",
        "attr = [[3,3,0],[16,0,0],[20,3,5],[18,0,0],[19,1,1],[10,0,0],[31,0,0],[16,0,0],[15,4,0],[4,0,0],[23,7,6]]\n",
        "unique = [[3,0,0],[4,0,0],[4,0,0],[4,0,0],[4,0,0],[3,0,0],[5,0,0],[4,0,0],[4,0,0],[4,0,0],[8,0,2]]\n",
        "composite = [[0,0,0],[0,0,0],[4,0,0],[0,0,0],[0,1,0],[0,0,0],[0,0,0],[0,0,0],[0,0,0],[0,0,0], [0,0,0]]\n",
        "multivalued = [[0,0,0],[0,0,0],[0,3,0],[0,0,0],[0,0,0],[0,0,0],[0,0,0],[0,0,0],[1,0,0], [0,0,0],[0,1,0]]\n",
        "relation = [[3,0,0],[1,2,2],[5,8,2],[2,1,2],[2,1,2],[2,1,0],[6,0,0],[1,2,1],[3,4,1], [4,0,0],[8,1,3]]"
      ],
      "metadata": {
        "id": "fzSc_NntvOR7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ent_np_prompt_train = np.array(ent)\n",
        "attr_np_prompt_train = np.array(attr)\n",
        "unique_np_prompt_train = np.array(unique)\n",
        "composite_np_prompt_train = np.array(composite)\n",
        "multivalued_np_prompt_train = np.array(multivalued)\n",
        "relation_np_prompt_train = np.array(relation)\n",
        "\n",
        "sum_ent_prompt_train = np.sum(ent_np_prompt_train, axis=0)\n",
        "sum_attr_prompt_train = np.sum(attr_np_prompt_train, axis=0)\n",
        "sum_unique_prompt_train = np.sum(unique_np_prompt_train, axis=0)\n",
        "sum_composite_prompt_train = np.sum(composite_np_prompt_train, axis=0)\n",
        "sum_multivalued_prompt_train = np.sum(multivalued_np_prompt_train, axis=0)\n",
        "sum_relation_prompt_train = np.sum(relation_np_prompt_train, axis=0)\n",
        "\n",
        "print('ent tp, fp and fn:',sum_ent_prompt_train)\n",
        "print('attr tp, fp and fn:',sum_attr_prompt_train)\n",
        "print('unique tp, fp and fn:',sum_unique_prompt_train)\n",
        "print('composite tp, fp and fn:',sum_composite_prompt_train)\n",
        "print('multivalued tp, fp and fn:',sum_multivalued_prompt_train)\n",
        "print('relationships tp, fp and fn:',sum_relation_prompt_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "51Il0aVT1Zaa",
        "outputId": "2f84340c-679c-404f-f26b-788971b6714e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ent: [53  9  1]\n",
            "attr: [175  18  12]\n",
            "unique: [47  0  2]\n",
            "composite: [4 1 0]\n",
            "multivalued: [1 4 0]\n",
            "relationships: [37 20 13]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ent_prec_train = precision(sum_ent_prompt_train[0], sum_ent_prompt_train[1])\n",
        "ent_rec_train = recall(sum_ent_prompt_train[0], sum_ent_prompt_train[2])\n",
        "ent_f1_train = f1(ent_prec_train, ent_rec_train)\n",
        "\n",
        "print('ent precision, recall and F1 score:', ent_prec_train, ent_rec_train, ent_f1_train)\n",
        "\n",
        "attr_prec_train = precision(sum_attr_prompt_train[0], sum_attr_prompt_train[1])\n",
        "attr_rec_train = recall(sum_attr_prompt_train[0], sum_attr_prompt_train[2])\n",
        "attr_f1_train = f1(attr_prec_train, attr_rec_train)\n",
        "\n",
        "print('attr precision, recall and F1 score:', attr_prec_train, attr_rec_train, attr_f1_train)\n",
        "\n",
        "unique_prec_train = precision(sum_unique_prompt_train[0], sum_unique_prompt_train[1])\n",
        "unique_rec_train = recall(sum_unique_prompt_train[0], sum_unique_prompt_train[2])\n",
        "unique_f1_train = f1(unique_prec_train, unique_rec_train)\n",
        "\n",
        "print('unique precision, recall and F1 score:', unique_prec_train, unique_rec_train, unique_f1_train)\n",
        "\n",
        "composite_prec_train = precision(sum_composite_prompt_train[0], sum_composite_prompt_train[1])\n",
        "composite_rec_train = recall(sum_composite_prompt_train[0], sum_composite_prompt_train[2])\n",
        "composite_f1_train = f1(composite_prec_train, composite_rec_train)\n",
        "\n",
        "print('composite precision, recall and F1 score:', composite_prec_train, composite_rec_train, composite_f1_train)\n",
        "\n",
        "multivalued_prec_train = precision(sum_multivalued_prompt_train[0], sum_multivalued_prompt_train[1])\n",
        "multivalued_rec_train = recall(sum_multivalued_prompt_train[0], sum_multivalued_prompt_train[2])\n",
        "multivalued_f1_train = f1(multivalued_prec_train, multivalued_rec_train)\n",
        "\n",
        "print('multivalued precision, recall and F1 score:', multivalued_prec_train, multivalued_rec_train, multivalued_f1_train)\n",
        "\n",
        "relation_prec_train = precision(sum_relation_prompt_train[0], sum_relation_prompt_train[1])\n",
        "relation_rec_train = recall(sum_relation_prompt_train[0], sum_relation_prompt_train[2])\n",
        "relation_f1_train = f1(relation_prec_train, relation_rec_train)\n",
        "\n",
        "print('relation precision, recall and F1 score:', relation_prec_train, relation_rec_train, relation_f1_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IJBfI0te1a47",
        "outputId": "6bc6e768-c75e-4360-97e4-68e16f995f8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ent: 0.8548387096774194 0.9814814814814815 0.9137931034482759\n",
            "attr: 0.9067357512953368 0.9358288770053476 0.9210526315789473\n",
            "unique: 1.0 0.9591836734693877 0.9791666666666666\n",
            "composite: 0.8 1.0 0.888888888888889\n",
            "multivalued: 0.2 1.0 0.33333333333333337\n",
            "relation: 0.6491228070175439 0.74 0.6915887850467289\n"
          ]
        }
      ]
    }
  ]
}